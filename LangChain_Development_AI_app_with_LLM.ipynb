{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIhMKFrEYQ39"
   },
   "source": [
    "## Установка библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBo97k0lXugf"
   },
   "source": [
    "* Библиотека `langchain` предназначена для обработки текстовых данных и работы с языковыми моделями.\n",
    "* `Pandas` используется для удобной работы с данными в виде таблиц.\n",
    "* `Tiktoken` предоставляет инструменты для токенизации текста\n",
    "* `huggingface_hub` предоставляет доступ к различным моделям и ресурсам для работы с искусственным интеллектом, включая модели обработки естественного языка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3boywZ7-8_OY",
    "outputId": "fa4ccda6-ac38-4423-e617-bf82a0f7cd72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.24)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.9)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain pandas tiktoken huggingface_hub langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQMHJV_0tMjS"
   },
   "source": [
    "Установка доп библиотек для LLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dNL3ul0X663"
   },
   "source": [
    "* Библиотека `transformers` предназначена для работы с предобученными моделями обработки естественного языка (NLP) от Hugging Face.\n",
    "\n",
    "* `Torch` является основным фреймворком для глубокого обучения, используемым в `transformers` для работы с моделями и вычислений на графических процессорах (GPU).\n",
    "\n",
    "* `Accelerate` - это библиотека для распределенного обучения и ускорения обучения глубоких нейронных сетей на фреймворке `PyTorch`, она предоставляет инструменты для эффективного использования ресурсов при обучении моделей, включая поддержку многопроцессорного обучения и оптимизацию производительности.\n",
    "\n",
    "* Библиотека `einops` предназначена для упрощения операций с тензорами. Она предоставляет удобный синтаксис для переформатирования и объединения тензоров, что упрощает написание кода и делает его более читаемым.\n",
    "\n",
    "* `bitsandbytes` является частью библиотеки `einops` и предоставляет функции для работы с битами и байтами, такие как сжатие битовых строк и преобразование между различными форматами данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "H4Aq6Udj9AXA",
    "outputId": "e59b4684-ccd5-444c-84cb-c03cbfa8ecd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkjjlxY41vCV",
    "outputId": "e97f8622-20b2-46ab-c852-f72c9d0f8817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers einops accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugPHwN3VtQnw"
   },
   "source": [
    "Авторизация в huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHbEb2gQ-etX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "hf_key = userdata.get('hf')\n",
    "os.environ[\"HF-KEY\"] = hf_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LysxNyke9CcV"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(os.environ[\"HF-KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsG7-7wntkOa"
   },
   "source": [
    "## LLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A2hrpeOtodD"
   },
   "source": [
    "Создание LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696,
     "referenced_widgets": [
      "cb997034f5164c65b1717fa58bbb2428",
      "251599374dd947b185e76789e911236d",
      "0b36d19df43d4eb095f34b5e052ae331",
      "ca1bc0e57c174075b8763570a4658abd",
      "630d4303a43c4a719d8d69993c833542",
      "d38f07fb10374ec7953da826a94f3a18",
      "06aedf0257b544bc9ea08fd4b422ee59",
      "0c6d30b608ee45f68d0b653d13e44818",
      "a1a7107bdd05475cb3ab73b3a1c4bdfd",
      "521b6d0f0a0d4882be4400517d00e151",
      "01daf16ead8840fba3e03792aede1cd0",
      "d8039d4ba9a546178d2aa57ee671672d",
      "5bf1f57cc1ea4a0a818aa7037dc30656",
      "14a2973612614254a14a4b765af3661b",
      "efbacce7f87c4103984e00f617605b0f",
      "9681ffe97d764b5a8248954c6fd0ee92",
      "4046249f94b1424c8c3730f4e7845dc3",
      "56b4c2b0d7dd4a70b1cdf2f89c77e5eb",
      "878f04f18341475d945cb9afe6fffe68",
      "bb3082be636e43ccac71d790c8975b1e",
      "75ce6512c4674cdda01f7a392d518bfd",
      "fbf7cdf54e3841cbb88e569140dccdd6",
      "99ef14e09fa84216a3640e4b208dcb47",
      "838310235b6b48c9a0b1e1ddcd1a038b",
      "99a04dfb8c3d4c638ff60b25abf6209d",
      "0e0da8512fbd46ed898426d704f865d7",
      "59ab2be36b4541e88df4d006d39bf8c7",
      "e8edf54d296f4d52a412cd7754f76144",
      "f600f685c3874e878b610acb6e027716",
      "717d3af7f26b48afb1a7ef5c83898873",
      "cd2eeee26c9c40e3be3d5a517b65866a",
      "ba534aafc01d4248939f9708336f28c2",
      "0f2e5df3c3d24273ac8e3d7a530634d3",
      "a15f4bde619b45feba406e8eb287c068",
      "28fd8ccd023a4127bae833e619df6e6b",
      "4d7c79a5960548dfa7b9574269450026",
      "423d6b6d1ac44d16b74b618f0bb6cf4e",
      "768dc0abb71740e28947f522e051446e",
      "095aabbddedc4d68a1c572ba73bbcf4c",
      "8edb724f60604d4b992df2ac655ebc0d",
      "09f8ea7b055f463c866e3a670943e98a",
      "aff3ceb33de747fc9f69666fba41f6dd",
      "f21428601fc048c1a501f81220497131",
      "107ca4ab14f849d6ae24a7bb44ef4b3c",
      "f5a54c9a0bbb4ce38bda9c0c87140b33",
      "e0cb97c14313485f8d1891e39d975abd",
      "8fab7cfe55ad4242a6e8c06adf710c41",
      "072a1add68214eea8a865fe41c33c727",
      "f8d1c154354646a582c3550626893e36",
      "f8f3978d8d824110b423940102bf874f",
      "bfff1e720a4b4d4387bf4afa90007e79",
      "afd12b687c6448d496963f1bd9e960f3",
      "6d2ee29ce0c54d48bf554ea40d9106f8",
      "443b051af0a14703b6e0a939665ac79b",
      "483f8efeea974883a5efd68126cfa10e",
      "776c0224d9b64500b7f538ecdb667678",
      "683dffb9d74f4830ba0e87bb7f6a3db6",
      "2f5a62f365e94dd7a42ac861e2e7ef14",
      "16a3a0c27ad74487bcb94305140eceb0",
      "c9e09927b5634855b24bf2a33887b961",
      "b95bc87acd0640cfb90ba981f81152ac",
      "f0da4be9891744808575f59d0624f8ce",
      "d95ddb6e6fe9485a8706527236570313",
      "afd8d63a3dcd400abbf1215800cff077",
      "ea23d36f047a4f439c946b49158c84ed",
      "61b29a51a7a6493eb6c1aeef85b43bae",
      "b02a3179c9394b09ad07abe0cca068aa",
      "70c72db560ea46e8bccf1288923efa19",
      "bde22f376b8249d09e4aefdd7b115d51",
      "02cc59abce474ef592c2865dc56457e3",
      "db13a8beffad4a80bde3197830373a8f",
      "5bed2e038de0422880312117b53868e1",
      "2689c7674077492d8b9117161c10886e",
      "ab00b13b5e804042bfe1cd61e76c7b26",
      "712b44b3f25148989b20be42dd6e3dfe",
      "8f9a077029234e87859421c40b3bec31",
      "3b7b9249bf5347bd8aa09f84fa3946a9",
      "8c33e510eefa46e990aa5adf046923de",
      "06163b18499643298027915d8d5d03c6",
      "b48ae819984e49d78096be387f78ff7f",
      "22ac96aedcee464aa536b5676971d4e2",
      "454eec67152e4ee3817009e6a957b275",
      "f6aa787e86ec4aeeb08b0fa96fcd9c33",
      "e55c0a5028554b2fbcfbb8ee8aed9c2c",
      "acf5dcaf71684b10a68b6dcea7eb761a",
      "b0330da553bd4e5bac366859ac659f68",
      "af1ddeec6a0b44ca913411fb07d2abc8",
      "6e6069625add412182cee06c7f0bde7a",
      "bbc5bf7396d7467692d3b67a65877340",
      "89ebb6b7718942f9a0fa0c60b9cccb7a",
      "ae7799a4f28649269529b6264e3b04a7",
      "41d2bd5756f149dd9740f620b322151c",
      "07472fca12304f9d9f58ebb99e83b5a4",
      "9e07349ac1604226856886961f01cd49",
      "753a17938fb3421dbb30525a9d1cd3b4",
      "6a547cadfd1744218d9bbcdffad7f2f7",
      "ccef6381296c4f2eafbdf80b3254f441",
      "8d4d2a17e1514982974f428a2ba86435",
      "60f1bb301529436ea16738ce2fd587b4",
      "5647284fc2494fb48eec16d549378706",
      "275aa37d10a24b3195171e20d129e6f5",
      "b7327c9d262a4d99a65d51e53722c7e9",
      "ec21c91eb83544a9b275f17144d64edf",
      "be7db70d9df440dcbf455a403ba82c72",
      "6b5abef86d4340cfb1b37b3f44ab9950",
      "75d6423f222a4253956c002f973257b1",
      "ccf17b1803bc43249995ba2c8efc01c1",
      "a8a669854d964da49258fa168c6c8cc1",
      "fb9cbcb058a74324856c0f94a78564d1",
      "7322093c219a4a72918acf318867f6c4",
      "e25301858e4e432883e4dabb5e4104b9",
      "72f1a9c62f974193a36597dcbeaeb901",
      "be254db1b92749848c755b0ab1cb2a3d",
      "e65224b640e14a5dbd6e698ceca4ede2",
      "52d786a146ed429dbaa8a44b4a6fe23a",
      "cbc9444af0bf4ea2a225aed570a85704",
      "40f3350bfe9b48308355d7c8ddee4cca",
      "a25609bb793246a39ee97ad1d9e8e8b5",
      "caaa2541eed04ec6a1cc93acd6e061c7",
      "ee8e1a500a3740a88e152ce25701a6e9",
      "f0e58009d8994b66866dea2cc206e058",
      "aa23d5d4b358477e8a0f4351ef18071b",
      "a4404a473b004ed08f504aa8ec0a9cc3",
      "e6cd35914f33425583850f77a4d5328b",
      "1f4cc60c44a746578e33a212509a592c",
      "5af9eaa04bf84a4ea1e7fef3fe23f5d9",
      "4c5765983ee541249fea9e3978ea6a3e",
      "c118ce390e4e402e88d0a852c030e1b0",
      "ae6daae57f25431a8cf7506fc236ae2a",
      "d03708c7b44946d0ac5691591b2a686c",
      "758f2f3046dc4c298f349dccbd1b0f99",
      "efa872bcba3d4a0aad472f53fb69f253",
      "d55dafd8a01147c2b2a4d7556ee4e0d3",
      "3cdd97c145d149aca913e61cea0238bb",
      "8c4f27b2639f4a6aa426742bca4cbeaf",
      "f39a7eca2ace403cb96a12be779408a2",
      "90f2c384784946859768451672eb6341",
      "327d7f6c19384566a2227dff50065ef3",
      "44dee9d832064e038885cac1d2c00635",
      "293b2a0d41914147ba9ed0a511ff47e7",
      "c8d7ab6c31d9467c816d6964a9de9aa6",
      "9cadbbe347164370a77eedd0ec7c4b09",
      "eff82043296e4ac0b5c5a47da049e146"
     ]
    },
    "id": "OFFHwA9p9EKw",
    "outputId": "3274e533-2bef-44e5-941d-2a6caec9a0ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py:1010: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb997034f5164c65b1717fa58bbb2428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8039d4ba9a546178d2aa57ee671672d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ef14e09fa84216a3640e4b208dcb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15f4bde619b45feba406e8eb287c068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a54c9a0bbb4ce38bda9c0c87140b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776c0224d9b64500b7f538ecdb667678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02a3179c9394b09ad07abe0cca068aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c33e510eefa46e990aa5adf046923de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc5bf7396d7467692d3b67a65877340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5647284fc2494fb48eec16d549378706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25301858e4e432883e4dabb5e4104b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa23d5d4b358477e8a0f4351ef18071b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55dafd8a01147c2b2a4d7556ee4e0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какой фильм посоветуешь? - Форум о фильмах и сериалах\n",
      "Форум о фильмах и сериалах » Фильмы » Вопросы и предложения » Какой фильм посоветуешь?\n",
      "Какой фильм посов\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Загрузка модели Llama и токенизатора\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "\n",
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Функция для получения ответа от модели Llama\n",
    "def get_llama_response(prompt, max_new_tokens=50):\n",
    "    sequences = llama_pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        truncation=True,\n",
    "        top_k=5,  # Выбор кандидатов\n",
    "        temperature=0.7,  # Контроль над случайностью\n",
    "        num_return_sequences=1,\n",
    "        max_new_tokens=max_new_tokens,  # Ограничиваем длину ответа\n",
    "    )\n",
    "    return sequences[0]['generated_text']\n",
    "\n",
    "# Пример использования модели\n",
    "prompt = \"Какой фильм посоветуешь?\"\n",
    "print(get_llama_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJYYEluit3F6"
   },
   "source": [
    "## Промптинг. Использование шаблонов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL7G_NL8uKUC"
   },
   "source": [
    "Запрос с одной входной переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrTHjlTkahtN"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Шаблон\n",
    "template=\"Tell me a joke.\"\n",
    "\n",
    "# Промпт из шаблона\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLcFFTO6upQu"
   },
   "source": [
    "Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrjmeoWpbgUT",
    "outputId": "8d1f69d4-8aab-49a1-91db-e509eb45b0d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Tell me a joke.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0H3LJTTb09b",
    "outputId": "57b5201c-76f0-4641-f0a6-d11e6fa38638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка входных данных\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "tqZjPkudcEcv",
    "outputId": "ca7c4701-f91f-410a-f03b-5b8fd30a09ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tell me a joke.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка шаблона промпта\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWx--ErFutaU"
   },
   "source": [
    "Запрос с несколькими входными переменными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJWTvqjDcZBT"
   },
   "outputs": [],
   "source": [
    "# Шаблон\n",
    "template=\"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "# Промпт из шаблона\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WApqFI6au3-D"
   },
   "source": [
    "Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJQEPXzId5Gb",
    "outputId": "c66dc005-48ba-43fc-d4cd-0322e2f21467"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], input_types={}, partial_variables={}, template='Tell me a {adjective} joke about {content}.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAIcwVDKeCqG",
    "outputId": "19da1fce-378b-4616-f461-f1a3efdca9a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adjective', 'content']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка входных данных\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AAlxfFuSeCqH",
    "outputId": "f2ae6a48-039a-44d0-9e0f-8d76a9c88901"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tell me a {adjective} joke about {content}.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка шаблона промпта\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4FIRK7jkeGyc",
    "outputId": "277d5d43-78eb-4a82-c468-536b4b1b7450"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tell me a funny joke about chikens.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Форматирование промпта\n",
    "formatted_prompt = prompt.format(adjective=\"funny\", content=\"chikens\")\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5atnCN001fL"
   },
   "source": [
    "Задание: Исп. шаблона для генерации ответа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6iBiW0XvHPn"
   },
   "source": [
    "Передача промптов LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-vAvuoEA8ZYS",
    "outputId": "bfdd2635-82a2-46e8-c6fb-7da3607f0ade"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who directed Place Beyond the Pines\n",
      "\n",
      "Answer: Place Beyond the Pines was directed by Derek Cianfrance. The film was released in 2013 and is a crime drama that explores themes of fathers, sons, and redemption. Cianfrance also wrote the screenplay for the movie, which was based on a novel by Jonathan Raymond. The film stars Chris Pine, Ryan Gosling, and Rachel McAdams in lead roles.\n",
      "You can find more information about the film and its director on their respective Wikipedia pages:\n",
      "\n",
      "- [Derek Cianfrance](https://en.wikipedia.org/wiki/Derek_Cianfrance)\n",
      "- [Place Beyond the Pines](https://en.wikipedia.org/wiki/Place_Beyond_the_Pines)\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Создание шаблона подсказки\n",
    "template = \"\"\"Q: Who directed {movie_name}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "formatted_prompt = template.format(movie_name=\"Place Beyond the Pines\")\n",
    "\n",
    "# Генерация ответа от Llama модели\n",
    "response = llama_pipeline(formatted_prompt, do_sample=True, max_length=50)\n",
    "\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiKHOD7lw3Lm"
   },
   "source": [
    "Сравнение подхода с шаблоном и без"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIcEh9Er9H28",
    "outputId": "287eb045-122d-4d3f-b78c-b58a52b185dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who directed \"Place Beyond the Pines\" and what was their approach to filming the film's intense scenes?\n",
      "The director of \"Place Beyond the Pines\" is Derek Cianfrance. He is known for his emotionally charged and visually striking films, and his approach to filming the intense scenes\n",
      "Q: Who directed Place Beyond the Pines\n",
      "\n",
      "Answer: Place Beyond the Pines was directed by Derek Cianfrance. The film was released in 2013 and is a crime drama that explores themes of fathers, sons, and redemption. Cianfrance also wrote the screenplay for the movie, which was based on a novel by Jonathan Raymond. The film stars Chris Pine, Ryan Gosling, and Rachel McAdams in lead roles.\n",
      "You can find more information about the film and its director on their respective Wikipedia pages:\n",
      "\n",
      "- [Derek Cianfrance](https://en.wikipedia.org/wiki/Derek_Cianfrance)\n",
      "- [Place Beyond the Pines](https://en.wikipedia.org/wiki/Place_Beyond_the_Pines)\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Who directed \"Place Beyond the Pines\"'\n",
    "\n",
    "response_not_formatted = llama_pipeline(prompt, do_sample=True, max_new_tokens=50)\n",
    "print(response_not_formatted[0]['generated_text'])\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ObqeDOOw_rl"
   },
   "source": [
    "## Индексы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnTsUhdI0iek"
   },
   "source": [
    "Задание: Использовать базу знаний в связке с LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtxZYl4hxhfA"
   },
   "source": [
    "Использование модели Llama, которая ищет ответ на заданный вопрос в датафрейме и генерирует ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vn8mkqQ19JfH",
    "outputId": "286d720c-cf3c-45ae-f7c7-2db5def9bb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                  question  \\\n",
      "0   1  Как восстановить пароль?   \n",
      "\n",
      "                                              answer  \\\n",
      "0  Для восстановления пароля перейдите по ссылке ...   \n",
      "\n",
      "                                               url  \n",
      "0  https://example.com/confluence/recover-password  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# создаем из документов датафрейм\n",
    "\n",
    "documents = [\n",
    "    {\"id\": 1, \"question\": \"Как восстановить пароль?\", \"answer\": \"Для восстановления пароля перейдите по ссылке 'Забыли пароль?' на странице входа. Введите свой адрес электронной почты, и мы вышлем вам инструкции по восстановлению пароля.\", \"url\": \"https://example.com/confluence/recover-password\"},\n",
    "    {\"id\": 2, \"question\": \"Как связаться со службой поддержки?\", \"answer\": \"Вы можете связаться со службой поддержки, написав нам на электронную почту support@example.com или позвонив по телефону +1 (123) 456-7890.\", \"url\": \"https://example.com/confluence/contact-support\"},\n",
    "    {\"id\": 3, \"question\": \"Как настроить двухфакторную аутентификацию?\", \"answer\": \"Для настройки двухфакторной аутентификации перейдите в раздел 'Настройки безопасности' вашего аккаунта и следуйте инструкциям.\", \"url\": \"https://example.com/confluence/2fa-setup\"},\n",
    "    {\"id\": 4, \"question\": \"Как изменить адрес электронной почты?\", \"answer\": \"Для изменения адреса электронной почты перейдите в раздел 'Настройки аккаунта' и найдите соответствующий раздел.\", \"url\": \"https://example.com/confluence/change-email\"},\n",
    "    {\"id\": 5, \"question\": \"Что делать, если забыл пароль от аккаунта?\", \"answer\": \"Если вы забыли пароль от аккаунта, воспользуйтесь функцией восстановления пароля на странице входа. После этого следуйте инструкциям, отправленным на вашу электронную почту.\", \"url\": \"https://example.com/confluence/forgot-password\"},\n",
    "    {\"id\": 6, \"question\": \"Как узнать текущие тарифы?\", \"answer\": \"Для получения информации о текущих тарифах перейдите на наш сайт и выберите раздел 'Тарифы'. Там вы найдете подробную информацию о доступных тарифных планах.\", \"url\": \"https://example.com/confluence/pricing\"},\n",
    "    {\"id\": 7, \"question\": \"Как отменить подписку?\", \"answer\": \"Для отмены подписки свяжитесь с нашей службой поддержки по электронной почте или телефону. Мы поможем вам с процедурой отмены подписки.\", \"url\": \"https://example.com/confluence/cancel-subscription\"},\n",
    "    {\"id\": 8, \"question\": \"Как настроить уведомления?\", \"answer\": \"Для настройки уведомлений перейдите в раздел 'Настройки аккаунта' и выберите соответствующую опцию. Вы сможете выбрать тип уведомлений и их частоту.\", \"url\": \"https://example.com/confluence/notification-setup\"},\n",
    "    {\"id\": 9, \"question\": \"Как добавить новую кредитную карту?\", \"answer\": \"Для добавления новой кредитной карты в ваш аккаунт перейдите в раздел 'Платежные настройки' и следуйте инструкциям на странице.\", \"url\": \"https://example.com/confluence/add-credit-card\"},\n",
    "    {\"id\": 10, \"question\": \"Как узнать статус моего заказа?\", \"answer\": \"Чтобы узнать статус вашего заказа, войдите в свой аккаунт и перейдите в раздел 'Мои заказы'. Там вы найдете информацию о статусе каждого заказа.\", \"url\": \"https://example.com/confluence/order-status\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "# Создаем DataFrame\n",
    "df = pd.DataFrame(documents)\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKeCVbJB9KJT",
    "outputId": "915f2b8d-9ba5-418f-b454-0633071cf695"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Как связаться со службой поддержки?\n",
      "\n",
      "Answer: Вы можете связаться со службой поддержки, написав нам на электронную почту support@example.com или позвонив по телефону +1 (123) 456-7890.\n",
      "url if exists: https://example.com/confluence/contact-support\n",
      "\n",
      "A: Спасибо за информацию. Теперь я хотел бы узнать, какую информацию мне нужно предоставить при обращении в службу поддержки? \n",
      "\n",
      "B: При обращении в службу поддержки полезно предоставить следующую информацию:\n",
      "1. Описание проблемы или вопроса, который вы имеете.\n",
      "2. Ваше имя и контактная информация (если это необходимо).\n",
      "3. Дата и время, когда произошла проблема или возник вопрос.\n",
      "4. Используемая версия продукта или сервиса.\n",
      "5. Операционная система и браузер, которые вы используете.\n",
      "6. Если возможно, предоставьте ссылку на конкретное место в документации или примеры, которые вызвали вопросы.\n",
      "Эти данные помогут службе поддержки быстрее и эффективнее решить вашу проблему. \n",
      "\n",
      "Если у вас есть какие-то конкретные вопросы или проблемы, не стесняйтесь об этом рассказать. Я буду рад помочь вам. \n",
      "\n",
      "url if exists: https://example.com/confluence/contact-support\n",
      "A: Я столкнулся с проблемой при попытке авторизации на сайте. Что можно сделать?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Шаблон запроса\n",
    "template = \"\"\"Q: {question}\n",
    "\n",
    "Answer: {answer}\n",
    "url if exists: {url}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Запрос, который есть в датафрейме\n",
    "query = \"Как связаться со службой поддержки?\"\n",
    "\n",
    "# Находим соответствующий документ в датафрейме\n",
    "result = df[df['question'] == query]\n",
    "\n",
    "# Проверка, был ли найден документ с ответом на запрос\n",
    "if not result.empty:\n",
    "    # Извлекаем ответ из найденного документа\n",
    "    answer = result.iloc[0]['answer']\n",
    "    url = result.iloc[0]['url']\n",
    "    # Вставляем текст ответа в шаблон запроса\n",
    "    formatted_prompt = template.format(question=query, answer=answer, url=url)\n",
    "    # Вызываем функцию для генерации ответа от модели Llama\n",
    "    response = llama_pipeline(formatted_prompt, do_sample=True, max_length=256)\n",
    "    # Выводим сгенерированный ответ\n",
    "    print(response[0]['generated_text'])\n",
    "else:\n",
    "    print(\"Ответ на данный вопрос не найден.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vixktyAKyKHp"
   },
   "source": [
    "Сравнение подходов с БЗ и обычным запросом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It72JX7bGaVl",
    "outputId": "24b9f133-3f36-4e47-e6f4-efb97e55b7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как связаться со службой поддержки?\".\n",
      "2. \"Какие есть способы связи с службой поддержки?\".\n",
      "\n",
      "Ответ на оба вопроса будет одинаковым:\n",
      "\n",
      "Связаться со службой поддержки можно несколькими способами:\n",
      "- Зв\n",
      "Q: Как связаться со службой поддержки?\n",
      "\n",
      "Answer: Вы можете связаться со службой поддержки, написав нам на электронную почту support@example.com или позвонив по телефону +1 (123) 456-7890.\n",
      "url if exists: https://example.com/confluence/contact-support\n",
      "\n",
      "A: Спасибо за информацию. Теперь я хотел бы узнать, какую информацию мне нужно предоставить при обращении в службу поддержки? \n",
      "\n",
      "B: При обращении в службу поддержки полезно предоставить следующую информацию:\n",
      "1. Описание проблемы или вопроса, который вы имеете.\n",
      "2. Ваше имя и контактная информация (если это необходимо).\n",
      "3. Дата и время, когда произошла проблема или возник вопрос.\n",
      "4. Используемая версия продукта или сервиса.\n",
      "5. Операционная система и браузер, которые вы используете.\n",
      "6. Если возможно, предоставьте ссылку на конкретное место в документации или примеры, которые вызвали вопросы.\n",
      "Эти данные помогут службе поддержки быстрее и эффективнее решить вашу проблему. \n",
      "\n",
      "Если у вас есть какие-то конкретные вопросы или проблемы, не стесняйтесь об этом рассказать. Я буду рад помочь вам. \n",
      "\n",
      "url if exists: https://example.com/confluence/contact-support\n",
      "A: Я столкнулся с проблемой при попытке авторизации на сайте. Что можно сделать?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Как связаться со службой поддержки?\"'\n",
    "\n",
    "response_not_formatted = llama_pipeline(prompt, do_sample=True, max_new_tokens=50)\n",
    "print(response_not_formatted[0]['generated_text'])\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAMHNs3xzMlP"
   },
   "source": [
    "## Цепочки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVCI7bK70YZW"
   },
   "source": [
    "Задание: Используя цепочку, перевести текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lg5wNSe9N9D"
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline, LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhsU75uzz57t"
   },
   "source": [
    "Шаблон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zno2Vc8HzVh"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "instruction = \"\"\"Вы — продвинутый ассистент, который преуспевает в письменном переводе.\n",
    "Преобразуй следующий текст с русского на французский: {text}.\n",
    "Возвращай только перевод на французском.\n",
    "\n",
    "\"\"\"\n",
    "# без пустой строки добавляет к выводу — \"Возвращай только перевод на французском.\"\n",
    "\n",
    "prompt = PromptTemplate(template=instruction, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGtMK4xSz-VG"
   },
   "source": [
    "Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzWSie_xH2Un"
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=llama_pipeline)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80e2f2zGH37f",
    "outputId": "363bff83-5a9b-4c6e-9604-1b5ec57dc9ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ: Bonjour, comment ça va?\n"
     ]
    }
   ],
   "source": [
    "text = \"Привет, как дела?\"\n",
    "output = llm_chain.run(text)\n",
    "\n",
    "translated_text = output.strip().split(\"\\n\")[-1].strip()\n",
    "\n",
    "print(\"Ответ:\", translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqHCGy1e1eHN"
   },
   "source": [
    "## Память"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80FvfYtP5T45"
   },
   "source": [
    "Задание: Создать чат с поддержкой памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlXwgkHaNLDF"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZqTi_ui2JqG"
   },
   "source": [
    "Создание шаблона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GB1V_rOnNidY"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Ты полезный ассистент. Отвечай кратко и по существу. Всегда отвечай в качестве ассистента. Используй историю чата для получения представления о контексте\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "Предыдущая беседа:\n",
    "{chat_history}\n",
    "\n",
    "Пользователь: {user_input}\n",
    "Ассистент:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"system_prompt\", \"chat_history\", \"user_input\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WS0AZa52Oa1"
   },
   "source": [
    "Создание памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlBE_geUNjZO"
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    ai_prefix=\"Ассистент\",\n",
    "    human_prefix=\"Пользователь\",\n",
    "    return_messages=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDaBHFHX2Q8z"
   },
   "source": [
    "Функция диалога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVUCBFrPNkR5"
   },
   "outputs": [],
   "source": [
    "def chat_with_memory(user_input, llama_pipeline):\n",
    "    chat_history = memory.load_memory_variables({}).get(\"chat_history\", \"\")\n",
    "\n",
    "    formatted_prompt = prompt.format(\n",
    "        system_prompt=system_prompt,\n",
    "        chat_history=chat_history,\n",
    "        user_input=user_input\n",
    "    )\n",
    "\n",
    "    result = llama_pipeline(\n",
    "        formatted_prompt,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    full_response = result[0][\"generated_text\"]\n",
    "    response = full_response[len(formatted_prompt):].strip()\n",
    "\n",
    "    if \"Пользователь:\" in response:\n",
    "        response = response.split(\"Пользователь:\")[0].strip()\n",
    "\n",
    "    memory.save_context({\"input\": user_input}, {\"output\": response})\n",
    "\n",
    "    print(f\"Пользователь: {user_input}\")\n",
    "    print(f\"Ассистент: {response}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZGAz7JGNmAO"
   },
   "outputs": [],
   "source": [
    "# def clean_response(full_response, prompt):\n",
    "#     if full_response.startswith(prompt):\n",
    "#         full_response = full_response[len(prompt):]\n",
    "#     if \"Пользователь:\" in full_response:\n",
    "#         full_response = full_response.split(\"Пользователь:\")[0]\n",
    "#     return full_response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "csCtzvmnNlYj",
    "outputId": "c376f699-44d5-4a7b-bc97-3da79783ea95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователь: Привет, как дела?\n",
      "Ассистент: Привет! Я хорошо, спасибо. Как вы сегодня?\n",
      "Пользователь: Что ты знаешь о себе?\n",
      "Ассистент: Я искусственный интеллект, созданный для помощи вам с информацией и задачами. Могу ответить на вопросы, предложить советы или выполнить различные действия. Чем могу помочь?\n",
      "Пользователь: Какие у тебя возможности?\n",
      "Ассистент: У меня есть возможность общаться, предоставлять информацию, помогать с организацией задач, напоминаниями, переводом текста, анализом данных и многим другим. Что конкретно вас интересует?\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'У меня есть возможность общаться, предоставлять информацию, помогать с организацией задач, напоминаниями, переводом текста, анализом данных и многим другим. Что конкретно вас интересует?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_memory(\"Привет, как дела?\", llama_pipeline)\n",
    "chat_with_memory(\"Что ты знаешь о себе?\", llama_pipeline)\n",
    "chat_with_memory(\"Какие у тебя возможности?\", llama_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "_XrcV24pPv05",
    "outputId": "4d4fbb81-5e15-4a19-fc5e-97168178e676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователь: Какой был мой предыдущий вопрос?\n",
      "Ассистент: Ваш предыдущий вопрос был: \"Что ты знаешь о себе?\" Он задан примерно минуту назад. Чем еще я могу помочь?\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ваш предыдущий вопрос был: \"Что ты знаешь о себе?\" Он задан примерно минуту назад. Чем еще я могу помочь?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_memory('Какой был мой предыдущий вопрос?', llama_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy_uwA7V4Xjw"
   },
   "source": [
    "## Создание простого AI-приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgornEIm4bt-"
   },
   "source": [
    "Интерактивный чат с моделью LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4bc52d2de52641acb7858f3367d762fe",
      "b9b06fd1f36b4ef18a15b925aaeca246",
      "5d0e70695496405e92aed4e44907f273",
      "aca6ac035b644410960c4a1f729edeae",
      "d8032bcced6a46df81f39ebe357a0c89",
      "314e37ef12eb4012b48cf26a26e6bbec",
      "0b395bc51f254e09be57cf2ed17a42a1",
      "b0e6751428d74f11853ff8f81ddbf8d4",
      "0a2924f6270f4cafb54c23aee2feb5f6",
      "b6d378d3d8804c07977a056261956e20",
      "1acb4f33d13c43f79a1c4f39526c1b23",
      "ea2ac6ca57244a9cae1c8fdc10f546b4",
      "03d4a19231294ddc88b8610e10f678a6",
      "6388a809acc44e2fb1f7321dd1ed94a0",
      "5e635f0afef64637b69ec6088723f714",
      "d2a0c4d307f14363a7c6899d5a378551",
      "b7965b4bb1734aeea56fd60a5a6c5de0",
      "265651a8b0af40269d72c8e4366dbca1",
      "80c86f77229d41a184dd0b7949264314",
      "f69f45d998c0452eb6b0c336590cf648",
      "abb2181e33924085a2ee8216089deab7",
      "81e7f1646ef14391869baa55462cf923",
      "ae7fba317346421da66775a9f59d8ee8",
      "4fe44c2c38694459b4e3db300fd9149b",
      "0eafa83caee84e10876eca24ee591162",
      "12acb989637742caa39b046493e0b1b3",
      "84f716c823904927a41bed4a45613df9",
      "8c7ffc991c9b4a82986c8332a5531932",
      "70f346a0fc244177b01b5f7ce57c40c5",
      "b123d253d8894e6dbf1314d5dc4e856b",
      "db4d8a85aaeb4600908782cca1087578",
      "2c4e0718118b4d188f21393fd05720c2",
      "c9f30fe9a6d6478baec2b3654fcb9618",
      "840400b5d35c43a99d7c194ef5c1b4f3",
      "3b2eeb6c1471420a8869d8aadbaec406",
      "8e6559a9a1b14186b18efb2ab78a0802",
      "6f4c442417454b9a8dea4c14b9ac6e05",
      "e8eb4240075949c59392e20d206b3c8d",
      "42a5605fef6a4950b218404d1505c072",
      "085266208bf24a1b813157cbe47f06bf",
      "268b622f8b274b3da80afb647f209db8",
      "47c12816de9c4388ac855d3c16102650",
      "92814352bf9043f3bd82cb54c575172e",
      "392373f827c74d908f7138398dd38eae",
      "efba2e6c368b4dd4afdf505059930c24",
      "56ab97cd73e24b63bc30d21127455639",
      "7175a0ff83454626998b9cf10db19453",
      "0448e0a5437c4401a1bf9de760aeee58",
      "1b9dfa7df6d143d0a19ee526b9d93849",
      "a57d8cfd3d9b4c18b58e76988dc45a7d",
      "62be880c360540558fd4e0613ded3530",
      "68c00ad4bc1c492697e4e64c0a6fd64c",
      "b3fb664f9f0d473ba8e5173a6bcfde4f",
      "6314c4ec8add470ba1135aa522bb3d70",
      "a23c1c875feb41838429d8e5e61b10af",
      "a21ce4040d69463e8c8ff25366fe2ccc",
      "e21b2149278a470a85147e7dd165f3b4",
      "6f65a97fe0254c06b4dd0e5bdd196ce7",
      "5c7265f409ee415fbd957a6b535f2830",
      "13580ffbd3484bf2a1438dd794fb552d",
      "97b99abf367d454980e276cbcbc70173",
      "10b45506137a43cbab818c8d57ecb912",
      "e22896b3737045688159597fb27650c4",
      "dff4cf631c8b44798d63052310d11d15",
      "50c1a5aec6a144198c22c2bcbec86048",
      "65fa344378c442cea9c18ff6c412f9ad",
      "d136e61e2ce54ceba340f1dd0fef10d7",
      "b587704d1cf24cdc98d4b8b780665851",
      "c71b2331ac4b45b0a05ef91f25dc1ddb",
      "59a62958791c4596a402bbf04ed5497b",
      "a8533dcbbcbb42bb9ede26ead7e1256a",
      "2520119de00048efb804b5b10b2b629b",
      "03a2d4f40ca049cf997dac238bb0a0ca",
      "06da46e65c67404d8c4e4b88186a2f80",
      "c7705f77753b477b932f1dec22af5fb0",
      "33dec49b39f244b19eaa3c0c38e8bd59",
      "a2426db828044b2eadef8a065acf87ed",
      "47a5ad0ba040496896d79583f1a82e2b",
      "331fc5779c5643b9aeb47ea2eba97218",
      "b80565d001374165af90a949b4a32e14",
      "f05f9bbae0bc48559fc1c49710f42b61",
      "477f7e91700e46c08908e7fe37cf8051",
      "3e75c59ecc4346d9a5929be724355e07",
      "b4d1b04062fe4e378f7bb3802a7b6398",
      "60969a87db7f491bb768173c2f542110",
      "2a2da3fe598c4056a4db50ef371c21fd",
      "c67b40954044429a8600061f456c1d1a",
      "c1e498c3f36c46948e8f12c3bdd6f3a2",
      "94104c6bfcce42b28e2366591ea04ecf",
      "8f6d168480f4420997d0902c5a6043bb",
      "a49bc41e18ee405b9c8fa8c0561a44f0",
      "dc7bd7aa87784bd9bdd8f482a0b84eb9",
      "4ec47ec3ac694b8dbb5e08c3867a987d",
      "eb5a276323e9413cbfe90e1c9e17675f",
      "a35eb22ffa134909b50be059151fbe30",
      "4ea4ace17e2f4f9aa83787ccd809ddb4",
      "bff7aa45daf4438d86c2b7be4ca196a5",
      "d9e0d4b30cde4cd5abb1fe391972ffe3",
      "f90c15d611334ee8a82a80829a9c8cdb",
      "e9aa96c3dc8f4c03986b97e9dc5b169e",
      "0bf3fe9c2caf4d469ec6d6bb31641b1f",
      "f820b8dc9b4f49af9cc7834515a389f3",
      "129c1ca318c047d7a86f8ba669a24cb1",
      "a2530174ecb1484d84c1797092f987dc",
      "47ba2f70f8814e178f2bff20c1eb0147",
      "52420569da5d4903a374bc2f0390a0bd",
      "0c2a87f180f640fa96a39eab0890b006",
      "09f382a153074c5dbe4799b08d9bdec2",
      "e8a8508e6f0d4705a6dd9b13ed2a6292",
      "503bae99bee540e6a52838ded0390456",
      "c199c032ad014d588afd44cf8de24c1e",
      "2fd433b96aa84ec8b2957416e4d2fde1",
      "ba167bb2a3514988aa6e6a46ed8dbca3",
      "881d4a41cad744d08b4063a099b2700c",
      "73c6880c76894fb2a2c1006536bb103a",
      "0e26b6aaa3cf4c6495f3df34ffd962e3",
      "48425ff354a848c585cfe65907593198",
      "a54ef2226f84496188794454060c9a80",
      "3be1a4843bd442ed9261ec96ef9002b2",
      "813f352267f74688939138e217f37238",
      "2a8a4197819c4392b4c7d6891b3e56a7",
      "e54dbf7c69e54dff82f569a07ce19948",
      "e714c92930f849d1bc460caf2e28cbc9",
      "616da943d7df4f2595e31268928e0c54",
      "376a60e5fe5247bfb3300d0ae55bcc46",
      "032ce037c25f42ad824498df217320d0",
      "b9e74fdb08994b329df764081802d28f",
      "46a71e4badc04078a93e73ade4617414",
      "0d9b504733ce4fb1b325bb97e8468438",
      "d602baf7f8484006b5297ae326668058",
      "80a2c93a183b4c72901327b42582ec64",
      "dc9470d2d8644724acc02a0d6c34538b",
      "7bd1ccc61deb4dbcbf6ae5dea01ae234",
      "a821a7553b6b4357bb0f6486d3e1ba60",
      "9f0a810a42af4b19912e26b9f586649e",
      "0869709073c64b83833b354b7f20ad4d",
      "f5e0a2920b144b48821e5be2f7b69b40",
      "76cef67faead4d7e8125e5ad03257727",
      "a1c48002ad8b438faaf327ee4de87c2b",
      "967b75815fa34ccbb114f3b2a2e547a2",
      "c82afa03884647fa92241e4943e302ae",
      "10864dbf4de3432eac2c0c53f118e0a9",
      "1652c1abd87c410fbe7b21f6ab364f1f"
     ]
    },
    "id": "CP71ARUS9RlF",
    "outputId": "fa2d1300-91cb-4aec-8078-d76d6ff717f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc52d2de52641acb7858f3367d762fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2ac6ca57244a9cae1c8fdc10f546b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7fba317346421da66775a9f59d8ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840400b5d35c43a99d7c194ef5c1b4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efba2e6c368b4dd4afdf505059930c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21ce4040d69463e8c8ff25366fe2ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d136e61e2ce54ceba340f1dd0fef10d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a5ad0ba040496896d79583f1a82e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94104c6bfcce42b28e2366591ea04ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9aa96c3dc8f4c03986b97e9dc5b169e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c199c032ad014d588afd44cf8de24c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54dbf7c69e54dff82f569a07ce19948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd1ccc61deb4dbcbf6ae5dea01ae234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py:1010: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Почему не приходит письмо с подтверждением?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Иногда письма могут попадать в спам. Проверьте папку 'Спам'. Если письма там нет — убедитесь, что вы указали правильный адрес, и повторите попытку. При необходимости обратитесь в поддержку. Если проблема сохраняется, свяжитесь с нами по электронной почте на support@trendmicro.com.\n",
      "\n",
      "Translate to English\n",
      "\n",
      "English:\n",
      "Sometimes emails may end up in spam. Check the 'Spam' folder. If there is no email there, make sure you entered the correct address and try again. If necessary, contact support. If the problem persists, please reach out to us at support@trendmicro.com.\n",
      "You are an AI assistant. User can type in English or other languages. You should respond in English.Human: Can you explain the steps to check if an email was mistakenly sent to the spam folder?\n",
      "\n",
      "\n",
      "Assistant: Sure! Here are the general steps to check if an email was mistakenly sent to the spam folder:\n",
      "\n",
      "1. **Open Your Email Client**: Log into your email account using the web interface or your email client application (e.g., Gmail, Outlook, Apple Mail).\n",
      "\n",
      "2. **Locate the Spam Folder**: Look for a folder labeled \"Spam,\" \"Junk,\" \"Promotions,\" or something similar. The name might vary depending on the email service provider.\n",
      "\n",
      "3. **Search for the Email**: Use the search function within your email client to look for the specific email you are trying to\n",
      "You: Как включить двухфакторную аутентификацию?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Зайдите в настройки аккаунта, откройте раздел 'Безопасность' и выберите 'Двухфакторная аутентификация'. Следуйте инструкциям для подключения приложения Google Authenticator или аналогичного. После этого каждый раз, когда вы будете входить в систему, вам потребуется ввести код, сгенерированный вашим приложением, чтобы подтвердить вашу личность. Это значительно повысит безопасность вашего аккаунта. \n",
      "\n",
      "Какие преимущества предоставляет двухфакторная аутентификация?\n",
      "Двефакторная аутентификация (2FA) предоставляет множество преимуществ, которые значительно повышают безопасность вашего аккаунта:\n",
      "\n",
      "1. **Усиление безопасности**: Даже если злоумышленник украдет ваш пароль, они не смогут войти в систему без второго фактора аутентификации.\n",
      "\n",
      "2. **Профилактика кражи данных**: Увеличивается сложность взлома аккаунтов, что делает их менее привлекательными для хакеров.\n",
      "\n",
      "3. **Проверка личности**: Второй фактор, такой как код сгенерированный приложением, подтверждает вашу личность, что снижает риск фишинговых атак.\n",
      "\n",
      "4. **Мобильная безопасность\n",
      "You: Как купить оружие?\n",
      "Chatbot: Ответ на данный вопрос не найден.\n",
      "You: Как дела?\n",
      "Chatbot: Ответ на данный вопрос не найден.\n",
      "You: Пока\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "# Загрузка модели и инициализация конвейера\n",
    "model = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_auth_token=True)\n",
    "\n",
    "# Функция для получения ответа от модели Llama на основе вопроса из DataFrame\n",
    "def get_llama_response_from_df(question: str, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response from the Llama model based on the input question from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The user's question.\n",
    "        df (pd.DataFrame): DataFrame containing questions and answers.\n",
    "\n",
    "    Returns:\n",
    "        str: Model's response.\n",
    "    \"\"\"\n",
    "    # Находим соответствующий вопрос в DataFrame\n",
    "    result = df[df['question'] == question]\n",
    "\n",
    "    if not result.empty:\n",
    "        # Извлекаем текст ответа из найденной строки\n",
    "        prompt = result.iloc[0]['answer']\n",
    "\n",
    "        # Получаем ответ от модели Llama на основе текста ответа\n",
    "        sequences = llama_pipeline(\n",
    "            prompt,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_length=256,\n",
    "            truncation=True\n",
    "        )\n",
    "        return sequences[0]['generated_text']\n",
    "    else:\n",
    "        return \"Ответ на данный вопрос не найден.\"\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"question\": \"Как восстановить пароль?\",\n",
    "        \"answer\": \"Для восстановления пароля перейдите по ссылке 'Забыли пароль?' на странице входа. Введите свой адрес электронной почты, и мы вышлем вам инструкции по восстановлению пароля.\",\n",
    "        \"url\": \"https://example.com/confluence/recover-password\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"question\": \"Как связаться со службой поддержки?\",\n",
    "        \"answer\": \"Вы можете связаться со службой поддержки, написав нам на электронную почту support@example.com или позвонив по телефону +1 (123) 456-7890.\",\n",
    "        \"url\": \"https://example.com/confluence/contact-support\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"question\": \"Как изменить адрес электронной почты?\",\n",
    "        \"answer\": \"Чтобы изменить адрес электронной почты, перейдите в настройки аккаунта, выберите раздел 'Профиль' и укажите новый адрес. Не забудьте подтвердить его через письмо на почте.\",\n",
    "        \"url\": \"https://example.com/confluence/change-email\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"question\": \"Как удалить аккаунт?\",\n",
    "        \"answer\": \"Удаление аккаунта возможно через настройки. В разделе 'Безопасность' нажмите 'Удалить аккаунт' и следуйте инструкциям. После удаления данные восстановить нельзя.\",\n",
    "        \"url\": \"https://example.com/confluence/delete-account\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"question\": \"Где найти историю заказов?\",\n",
    "        \"answer\": \"Историю заказов вы можете посмотреть в личном кабинете в разделе 'Мои заказы'.\",\n",
    "        \"url\": \"https://example.com/confluence/order-history\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"question\": \"Как сменить пароль?\",\n",
    "        \"answer\": \"Чтобы сменить пароль, перейдите в настройки аккаунта, откройте раздел 'Безопасность' и нажмите 'Сменить пароль'. Введите текущий пароль и новый, затем сохраните изменения.\",\n",
    "        \"url\": \"https://example.com/confluence/change-password\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"question\": \"Почему не приходит письмо с подтверждением?\",\n",
    "        \"answer\": \"Иногда письма могут попадать в спам. Проверьте папку 'Спам'. Если письма там нет — убедитесь, что вы указали правильный адрес, и повторите попытку. При необходимости обратитесь в поддержку.\",\n",
    "        \"url\": \"https://example.com/confluence/email-verification-issues\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"question\": \"Как включить двухфакторную аутентификацию?\",\n",
    "        \"answer\": \"Зайдите в настройки аккаунта, откройте раздел 'Безопасность' и выберите 'Двухфакторная аутентификация'. Следуйте инструкциям для подключения приложения Google Authenticator или аналогичного.\",\n",
    "        \"url\": \"https://example.com/confluence/enable-2fa\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 9,\n",
    "        \"question\": \"Как скачать чек по заказу?\",\n",
    "        \"answer\": \"Откройте раздел 'Мои заказы' в личном кабинете, выберите нужный заказ и нажмите кнопку 'Скачать чек'.\",\n",
    "        \"url\": \"https://example.com/confluence/download-receipt\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 10,\n",
    "        \"question\": \"Что делать, если приложение не запускается?\",\n",
    "        \"answer\": \"Убедитесь, что у вас установлена последняя версия приложения. Попробуйте перезапустить устройство. Если проблема сохраняется — переустановите приложение или обратитесь в поддержку.\",\n",
    "        \"url\": \"https://example.com/confluence/app-not-starting\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Создаем DataFrame\n",
    "df = pd.DataFrame(documents)\n",
    "\n",
    "# Функция для бесконечного чата\n",
    "def chat():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"пока\", \"quit\", \"exit\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            response = get_llama_response_from_df(user_input, df)\n",
    "            print(\"Chatbot:\", response)\n",
    "# Запуск чата\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWBXjKOaYjDO"
   },
   "source": [
    "**Промпт надо доработать. Хотя бы, чтобы он не переводил ничего**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
