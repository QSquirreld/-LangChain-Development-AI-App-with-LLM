# LangChain: Development AI-app with LLM

Проект реализует обзор основных подходов и функций LangChain. Их сравнение с базовым ответом. А также их применение в разработке ИИ приложений.

## Функциональность

1. LLM: Загрузка локальной модели LLaMA и инициализация пайплайна
2. Промптинг: Использование шаблонов для генерации
3. Индексы и документы: Работа LLM в связке с базой знаний. Поиск и RAG
4. Цепочки: Объединение модели и промптов в `LLMChain`
5. Память: Реализация диалога с поддержкой памяти
6. Простое AI-приложение: Чат-бот, отвечающий на вопросы из базы знаний совместно с RAG

## Используемые технологии

-   `LangChain`
-   Модель: `LLaMA` (локально через pipeline)
    - [`Qwen2.5-7B-Instruct`](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct),

## Возможные доработки

-   Добавить **интерактивный UI** через Streamlit
-   Подключить **векторный поиск** (RAG)
-   Реализовать **агентов с инструментами**

## Результат

-   Успешно реализована генерация ответов на основе шаблонов
-   Модель корректно реагирует на запросы и использует историю диалога
-   Чат-бот способен адаптироваться под данные из базы знаний и формировать осмысленные ответы

## Как использовать

1.  Установите зависимости
2.  Запустите ноутбук по шагам
3.  Модифицируйте шаблоны, добавьте свои данные или расширьте функциональность (например, подключение к внешней БД или использование инструментов)

## Связанные проекты

- [Improved Streamlit GigaChat App](https://github.com/QSquirreld/Improved-Streamlit-GigaChat-App) — Интерактивное веб-приложение на базе Streamlit для общения с GigaChat API.